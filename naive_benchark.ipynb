{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee670942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3cc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_mape(y, yhat):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    yhat = np.asarray(yhat, dtype=float)\n",
    "    mask = y != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return float(np.mean(np.abs((yhat[mask] - y[mask]) / y[mask])))\n",
    "\n",
    "\n",
    "def compute_naive_store_metrics(df, steps=54):\n",
    "    \"\"\"\n",
    "    df: long DataFrame with at least ['Store', 'Date', 'Sales']\n",
    "        assumed already filtered to the evaluation horizon (train+test)\n",
    "    steps: number of last days per store used as test set\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.sort_values([\"Store\", \"Date\"], inplace=True)\n",
    "\n",
    "    store_metrics = []\n",
    "\n",
    "    for store_id, g in df.groupby(\"Store\"):\n",
    "        g = g.sort_values(\"Date\")\n",
    "        y = g[\"Sales\"].to_numpy(dtype=float)\n",
    "\n",
    "        if len(y) <= steps:\n",
    "            # not enough history to form train+test\n",
    "            continue\n",
    "\n",
    "        # last `steps` days are test\n",
    "        test_y = y[-steps:]\n",
    "        # naive prediction: yesterday's sales\n",
    "        # for each test day t, use y_{t-1}\n",
    "        naive_pred = y[-steps-1:-1]  # same length as test_y\n",
    "\n",
    "        err = naive_pred - test_y  # prediction - actual\n",
    "\n",
    "        rows = len(test_y)\n",
    "        sales_sum = float(test_y.sum())\n",
    "        abs_err = np.abs(err)\n",
    "        abs_err_sum = float(abs_err.sum())\n",
    "        sq_err_sum = float((err ** 2).sum())\n",
    "\n",
    "        mae = float(abs_err.mean())\n",
    "        rmse = float(np.sqrt(sq_err_sum / rows))\n",
    "        mape = _safe_mape(test_y, naive_pred)\n",
    "        wape = abs_err_sum / sales_sum if sales_sum != 0 else np.nan\n",
    "\n",
    "        tae = float(np.abs(naive_pred.sum() - test_y.sum()))\n",
    "        bias = float(err.mean())\n",
    "        err_std = float(err.std(ddof=0))\n",
    "\n",
    "        # for global MAPE (true point-wise weighted MAPE)\n",
    "        mask = test_y != 0\n",
    "        abs_pct_err_sum = float(np.abs(err[mask] / test_y[mask]).sum())\n",
    "        nonzero_n = int(mask.sum())\n",
    "\n",
    "        store_metrics.append({\n",
    "            \"Store\": store_id,\n",
    "            \"rows\": rows,\n",
    "            \"sales_sum\": sales_sum,\n",
    "            \"wape\": wape,\n",
    "            \"bias\": bias,\n",
    "            \"err_std\": err_std,\n",
    "            \"TAE\": tae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE\": mape,\n",
    "            \"abs_err_sum\": abs_err_sum,\n",
    "            \"sq_err_sum\": sq_err_sum,\n",
    "            \"abs_pct_err_sum\": abs_pct_err_sum,\n",
    "            \"nonzero_n\": nonzero_n,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(store_metrics)\n",
    "\n",
    "\n",
    "def summarize_org_metrics(store_df):\n",
    "    \"\"\"\n",
    "    store_df: output of compute_naive_store_metrics\n",
    "    Returns a dict with organization-level metrics comparable\n",
    "    to those used for SARIMAX/XGBoost.\n",
    "    \"\"\"\n",
    "    total_sales = store_df[\"sales_sum\"].sum()\n",
    "    total_abs_err = store_df[\"abs_err_sum\"].sum()\n",
    "    total_sq_err = store_df[\"sq_err_sum\"].sum()\n",
    "    total_rows = store_df[\"rows\"].sum()\n",
    "\n",
    "    # global WAPE (org-level)\n",
    "    org_wape = total_abs_err / total_sales if total_sales != 0 else np.nan\n",
    "\n",
    "    # \"Weighted RMSE\" as RMSE over all store-day observations\n",
    "    org_weighted_rmse = np.sqrt(total_sq_err / total_rows) if total_rows > 0 else np.nan\n",
    "\n",
    "    # unweighted MAPE = simple average of store-level MAPEs\n",
    "    org_mape_unweighted = store_df[\"MAPE\"].mean()\n",
    "\n",
    "    # global point-wise MAPE (true weighted by number of nonzero points)\n",
    "    total_abs_pct_err = store_df[\"abs_pct_err_sum\"].sum()\n",
    "    total_nonzero = store_df[\"nonzero_n\"].sum()\n",
    "    org_mape_weighted = (total_abs_pct_err / total_nonzero) if total_nonzero > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"WAPE\": org_wape,\n",
    "        \"Weighted_RMSE\": org_weighted_rmse,\n",
    "        \"MAPE_weighted\": org_mape_weighted,\n",
    "        \"MAPE_unweighted\": org_mape_unweighted,\n",
    "        \"Total_sales\": total_sales,\n",
    "        \"Total_rows\": total_rows,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "777a20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = sqlite3.connect('rossmann.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Assign 'rossmann' table to Pandas DataFrame\n",
    "sql = \"SELECT * FROM rossmann\"\n",
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b25d07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  rows  sales_sum      wape        bias      err_std      TAE  \\\n",
      "0      1    54   204677.0  0.403186  -97.462963  2444.876758   5263.0   \n",
      "1      2    54   232766.0  0.448261 -112.296296  2750.712626   6064.0   \n",
      "2      3    54   327507.0  0.423362 -153.962963  3760.633777   8314.0   \n",
      "3      4    54   461174.0  0.427706 -259.166667  5622.940113  13995.0   \n",
      "4      5    54   214640.0  0.444372  -89.296296  2648.474688   4822.0   \n",
      "\n",
      "          RMSE      MAPE  abs_err_sum    sq_err_sum  abs_pct_err_sum  \\\n",
      "0  2446.818626  0.242496      82523.0  3.232938e+08        11.397315   \n",
      "1  2753.003888  0.352289     104340.0  4.092676e+08        16.557596   \n",
      "2  3763.784133  0.331275     138654.0  7.649678e+08        15.569921   \n",
      "3  5628.909563  0.260955     197247.0  1.710970e+09        12.264908   \n",
      "4  2649.979623  0.415378      95380.0  3.792092e+08        19.522751   \n",
      "\n",
      "   nonzero_n  \n",
      "0         47  \n",
      "1         47  \n",
      "2         47  \n",
      "3         47  \n",
      "4         47  \n",
      "       WAPE  Weighted_RMSE  MAPE_weighted  MAPE_unweighted  Total_sales  \\\n",
      "0  0.425271    4217.703942       0.302857         0.303331  368285251.0   \n",
      "\n",
      "   Total_rows  \n",
      "0       60210  \n"
     ]
    }
   ],
   "source": [
    "# df_all has columns: Store, Date, Sales, ...\n",
    "steps = 54\n",
    "\n",
    "# Store-level metrics\n",
    "naive_store_df = compute_naive_store_metrics(df, steps=steps)\n",
    "\n",
    "# Org-level metrics (dict)\n",
    "naive_org_summary_dict = summarize_org_metrics(naive_store_df)\n",
    "\n",
    "# Convert to single-row DataFrame\n",
    "naive_org_summary = pd.DataFrame([naive_org_summary_dict])\n",
    "\n",
    "print(naive_store_df.head())\n",
    "print(naive_org_summary)\n",
    "\n",
    "naive_store_df.to_csv(\"naive_store_metrics.csv\", index=False)\n",
    "naive_org_summary.to_csv(\"naive_org_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
